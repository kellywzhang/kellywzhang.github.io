<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://kellywzhang.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://kellywzhang.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-29T17:43:42+00:00</updated><id>https://kellywzhang.github.io/feed.xml</id><title type="html">blank</title><subtitle></subtitle><entry><title type="html">Posterior Sampling via Autoregressive Generation</title><link href="https://kellywzhang.github.io/blog/2024/ps-ar/" rel="alternate" type="text/html" title="Posterior Sampling via Autoregressive Generation"/><published>2024-05-29T00:00:00+00:00</published><updated>2024-05-29T00:00:00+00:00</updated><id>https://kellywzhang.github.io/blog/2024/ps-ar</id><content type="html" xml:base="https://kellywzhang.github.io/blog/2024/ps-ar/"><![CDATA[<h3 id="introdution">Introdution</h3> <p>Real-world decision-making often involves grappling with uncertainty This challenge is particularly acute in areas like recommendation systems, where new items are continuously introduced or BLAH BLAH. Traditional bandit algorithms struggle to handle the complex, unstructured data (e.g., text and images) that characterizes modern applications. This work introduces a novel framework for learning bandit algorithms using autoregressive sequence models, offering a scalable and principled approach to Thompson sampling.</p> <h3 id="our-approach">Our Approach</h3> <h4 id="we-propose-a-two-phase-solution">We propose a two-phase solution:</h4> <p><strong>Pretraining:</strong> We leverage historical data to train an autoregressive sequence model that predicts user feedback (e.g., clicks) on articles. The model learns a prior distribution over the engagement of articles based on their features (e.g., headlines).</p> <p><strong>Online Decision-Making:</strong> At decision time, we use the pretrained model to autoregressively sample imaginary sequences of user feedback for each article. We then choose the article with the highest average imputed reward, representing a sample from the posterior distribution of the articleâ€™s true engagement.</p> <h3 id="key-insights">Key Insights:</h3> <ul> <li>This approach is a principled implementation of Thompson sampling, a powerful algorithm for balancing exploration and exploitation.</li> <li>By sampling from the posterior distribution of article rewards, we directly address the uncertainty inherent in the decision-making process.</li> <li>Our framework leverages advances in autoregressive generative models (like transformers), allowing for scalability and integration with rich feature representations (e.g., article headlines).</li> </ul> <h3 id="theoretical-foundations">Theoretical Foundations</h3> <p>We prove a novel regret bound that links the online performance of our algorithm to the prediction loss of the pretrained sequence model. This provides a strong theoretical foundation for our approach.</p> <h3 id="empirical-evaluation">Empirical Evaluation:</h3> <p>We demonstrate our method on both synthetic and real-world news recommendation tasks. Our results show: <strong>Improved performance:</strong> Our approach outperforms traditional bandit algorithms, especially when using rich features like article headlines.</p> <p><strong>Uncertainty quantification:</strong> We can effectively estimate the uncertainty associated with article engagement, allowing for more informed decision-making.</p> <h3 id="conclusion">Conclusion:</h3> <p>By framing bandit problems as sequence modeling tasks, we have introduced a novel and scalable approach to Thompson sampling that is well-suited for modern, complex applications. Our framework leverages the power of autoregressive generative models, providing a strong theoretical foundation and promising empirical results.</p>]]></content><author><name>Kelly W. Zhang*</name></author><category term="bandit-algorithms,"/><category term="Thompson-sampling,"/><category term="generative-models"/><summary type="html"><![CDATA[Bridging Generative Sequence Modeling and Online Decision-Making]]></summary></entry></feed>