<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Kelly W. Zhang </title> <meta name="author" content="Kelly W. Zhang"> <meta name="description" content=""> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://kellywzhang.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/research/">Research </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Kelly</span> W. Zhang </h1> <p class="desc"><b>Lecturer (Assistant Professor) at Imperial College London</b></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/kelly_paris2-480.webp 480w,/assets/img/kelly_paris2-800.webp 800w,/assets/img/kelly_paris2-1400.webp 1400w," sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/kelly_paris2.jpeg?952010c6e2f944c283eef2f8c72d2441" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="kelly_paris2.jpeg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <center> <p>kelly.zhang@imperial.ac.uk</p> <p>[<a href="https://scholar.google.com/citations?user=VDwprrsAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Google Scholar</a>]</p> <br> <p>[<a href="https://github.com/kellywzhang" rel="external nofollow noopener" target="_blank">Github</a>]</p> <p>[<a href="https://twitter.com/kewzha" rel="external nofollow noopener" target="_blank">Twitter</a>]</p> <p>Office: <a href="https://www.imperial.ac.uk/i-hub/find-i-hub" rel="external nofollow noopener" target="_blank">I-HUB</a> Level 5, Pod 3</p> </center> </div> </div> <div class="clearfix"> <p>I am an Lecturer (UK version of Assistant Professor) at <a href="https://www.imperial.ac.uk/" target="_blank" rel="noopener noreferrer">Imperial College London</a> in the Mathematics Department (statistics section). I am also a faculty member in the <a href="https://ix.imperial.ac.uk/" target="_blank" rel="noopener noreferrer">I-X</a>, an interdisciplinary AI initiative at Imperial. My research interests lie at the intersection of <em>adaptive experimentation</em>, <em>reinforcement learning</em>, and <em>statistical inference</em>.</p> <p>I previously was a Postdoctoral Fellow at <a href="https://business.columbia.edu/" target="_blank" rel="noopener noreferrer">Columbia Business School</a> in the Descision, Risk, and Optimization group, working with <a href="https://djrusso.github.io/" target="_blank" rel="noopener noreferrer">Daniel Russo</a> and <a href="https://hsnamkoong.github.io/" rel="external nofollow noopener" target="_blank">Hongseok Namkoong</a>. I completed my Ph.D. student in computer science at <a href="https://www.harvard.edu/" target="_blank" rel="noopener noreferrer">Harvard University</a> in the <a href="http://people.seas.harvard.edu/~samurphy/lab/overview.html" target="_blank" rel="noopener noreferrer">Statistical Reinforcement Learning Lab</a>. I was advised by <a href="http://people.seas.harvard.edu/~samurphy/" target="_blank" rel="noopener noreferrer">Susan Murphy</a> and <a href="http://lucasjanson.fas.harvard.edu/" target="_blank" rel="noopener noreferrer">Lucas Janson</a>. I was supported by an NSF Graduate Fellowship during my PhD and was selected to be a <a href="https://www.siebelscholars.com/articles/welcome-class-of-2023-siebel-scholars/" target="_blank" rel="noopener noreferrer">Siebel Scholar</a> in 2023.</p> <p>Even earlier, I worked on natural language processing and deep learning with <a href="http://nlp.seas.harvard.edu/rush.html" target="_blank" rel="noopener noreferrer">Sasha Rush</a>, <a href="https://www.nyu.edu/projects/bowman/" target="_blank" rel="noopener noreferrer">Sam Bowman</a>, and <a href="http://yann.lecun.com/" target="_blank" rel="noopener noreferrer">Yann LeCun</a>. I also previously interned at <a href="https://www.apple.com/healthcare/" target="_blank" rel="noopener noreferrer">Apple’s HealthAI</a> team in Seattle, <a href="https://ai.meta.com/research/" target="_blank" rel="noopener noreferrer">Facebook AI Research</a> in New York, and at <a href="https://www.ebay.com/" target="_blank" rel="noopener noreferrer">eBay</a> New York on the homepage recommendations team.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Aug 14, 2024</th> <td> I am co-organizing a session at IMS-Bernoulli on the `Frontiers of Adaptive Experimentation’. The speakers will be Dean Foster, Maria Dimakopolou, Koulik Khamaru, and myself! </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 09, 2024</th> <td> Co-organizing workshop on <a href="https://deployable-rl.github.io/" rel="external nofollow noopener" target="_blank">Deployable RL: From Research to Practice</a> at RLC! Please come by!! </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 08, 2024</th> <td> I will be speaking at JSM in the session on <a href="https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=1674" rel="external nofollow noopener" target="_blank">Statistical Challenges and New Directions for Adaptive Experimentation</a> organized by Aaditya Ramdas! I will also chair the session on <a href="https://ww3.aievolution.com/JSMAnnual2024/Events/viewEv?ev=1321" rel="external nofollow noopener" target="_blank">New Methods in Causal Inference and Reinforcement Learning for Personalized Decision-Making</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">May 11, 2024</th> <td> I attended the ICLR workshop on <a href="https://sites.google.com/view/genai4dm-iclr2024" rel="external nofollow noopener" target="_blank">Generative Models for Decision Making</a> and presented our new work on <a href="https://arxiv.org/abs/2405.19466" rel="external nofollow noopener" target="_blank">Posterior Sampling via Autoregressive Generation</a><a>!</a> </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 06, 2023</th> <td> Speaking at the session on <a href="https://ww2.aievolution.com/JSMAnnual/index.cfm?do=ev.viewEv&amp;ev=1193" rel="external nofollow noopener" target="_blank">Integrating Algorithms and Analysis for Adaptively Randomized Experiments</a> at JSM in Toronto. The session is organized by John Langford, Sofia Villar, Aaditya Ramdas, Joseph Jay Williams, and Tong Li. </td> </tr> <tr> <th scope="row" style="width: 20%">Jul 28, 2023</th> <td> I was interviewed as a part of the <a href="https://statistics.fas.harvard.edu/news/postdoctoral-fellow-kelly-w-zhang-interviewed-women-statistics-and-data-science" target="_blank" rel="noopener noreferrer">Harvard Women in Statistics and Data Science Series</a>! </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 28, 2023</th> <td> I defended my thesis on <i>Statistical Inference for Adaptive Experimentation</i>. My slides are <a href="/assets/pdf/kelly_zhang_defense.pdf" target="_blank" rel="noopener noreferrer">here</a>. My thesis committee members were Susan Murphy, Lucas Janson, Milind Tambe, and Jonas Oddur Jonasson. </td> </tr> <tr> <th scope="row" style="width: 20%">Jun 28, 2022</th> <td> I organized an <a href="https://www.imsannualmeeting-london2022.com/invited-sessions" rel="external nofollow noopener" target="_blank">invited session at the 2022 Institute of Mathematical Statistics Annual Meeting</a> on <i>“Inference Methods for Adaptively Collected Data”</i>. The speakers will be Nathan Kallus, Koulik Khamaru, Evan Munro, and myself! Joseph Jay Williams and Nina Deliu will chair the session. </td> </tr> </table> </div> </div> <h2> <a href="/research/" style="color: inherit">Selected Papers</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#3aa6c1"> <div>Bandit/RL Algorithms</div> </abbr> </div> <div id="impatientBandits2025" class="col-sm-8"> <div class="title">Impatient Bandits: Optimizing for the Long-Term Without Delay</div> <div class="author"> Kelly W Zhang, Thomas Baldwin-McDonald, Kamil Ciosek, Lucas Maystre, and Daniel Russo </div> <div class="periodical"> <em>Preprint</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2501.07761" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Increasingly, recommender systems are tasked with improving users’ long-term satisfaction. In this context, we study a content exploration task, which we formalize as a bandit problem with delayed rewards. There is an apparent trade-off in choosing the learning signal: waiting for the full reward to become available might take several weeks, slowing the rate of learning, whereas using short-term proxy rewards reflects the actual long-term goal only imperfectly. First, we develop a predictive model of delayed rewards that incorporates all information obtained to date. Rewards as well as shorter-term surrogate outcomes are combined through a Bayesian filter to obtain a probabilistic belief. Second, we devise a bandit algorithm that quickly learns to identify content aligned with long-term success using this new predictive model. We prove a regret bound for our algorithm that depends on the Value of Progressive Feedback, an information theoretic metric that captures the quality of short-term leading indicators that are observed prior to the long-term reward. We apply our approach to a podcast recommendation problem, where we seek to recommend shows that users engage with repeatedly over two months. We empirically validate that our approach significantly outperforms methods that optimize for short-term proxies or rely solely on delayed rewards, as demonstrated by an A/B test in a recommendation system that serves hundreds of millions of users.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">impatientBandits2025</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Impatient Bandits: Optimizing for the Long-Term Without Delay}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Kelly W and Baldwin-McDonald, Thomas and Ciosek, Kamil and Maystre, Lucas and Russo, Daniel}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Preprint}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#3aa6c1"> <div>Bandit/RL Algorithms</div> </abbr> </div> <div id="psar2024" class="col-sm-8"> <div class="title">Posterior Sampling via Autoregressive Generation</div> <div class="author"> Kelly W Zhang*, Tiffany (Tianhui) Cai*, Hongseok Namkoong, and Daniel Russo </div> <div class="periodical"> <em>Preprint</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2405.19466" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Real-world decision-making requires grappling with a perpetual lack of data as environments change; intelligent agents must comprehend uncertainty and actively gather information to resolve it. We propose a new framework for learning bandit algorithms from massive historical data, which we demonstrate in a cold-start recommendation problem. First, we use historical data to pretrain an autoregressive model to predict a sequence of repeated feedback/rewards (e.g., responses to news articles shown to different users over time). In learning to make accurate predictions, the model implicitly learns an informed prior based on rich action features (e.g., article headlines) and how to sharpen beliefs as more rewards are gathered (e.g., clicks as each article is recommended). At decision-time, we autoregressively sample (impute) an imagined sequence of rewards for each action, and choose the action with the largest average imputed reward. Far from a heuristic, our approach is an implementation of Thompson sampling (with a learned prior), a prominent active exploration algorithm. We prove our pretraining loss directly controls online decision-making performance, and we demonstrate our framework on a news recommendation task where we integrate end-to-end fine-tuning of a pretrained language model to process news article headline text to improve performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">psar2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Posterior Sampling via Autoregressive Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang*, Kelly W and Cai*, Tiffany (Tianhui) and Namkoong, Hongseok and Russo, Daniel}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Preprint}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#5ac13a"> <div>Statistical Inference</div> </abbr> </div> <div id="zhang2021mestimator" class="col-sm-8"> <div class="title">Statistical Inference with M-Estimators on Adaptively Collected Data</div> <div class="author"> Kelly W Zhang, Lucas Janson, and Susan Murphy </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2104.14074" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.youtube.com/watch?v=jflR7KOrqNA&amp;t=2s" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/kellywzhang/adaptively_weighted_Mestimation" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Bandit algorithms are increasingly used in real-world sequential decision-making problems. Associated with this is an increased desire to be able to use the resulting datasets to answer scientific questions like: Did one type of ad lead to more purchases? In which contexts is a mobile health intervention effective? However, classical statistical approaches fail to provide valid confidence intervals when used with data collected with bandit algorithms. Alternative methods have recently been developed for simple models (e.g., comparison of means). Yet there is a lack of general methods for conducting statistical inference using more complex models on data collected with (contextual) bandit algorithms; for example, current methods cannot be used for valid inference on parameters in a logistic regression model for a binary reward. In this work, we develop theory justifying the use of M-estimators – which includes estimators based on empirical risk minimization as well as maximum likelihood – on data collected with adaptive algorithms, including (contextual) bandit algorithms. Specifically, we show that M-estimators, modified with particular adaptive weights, can be used to construct asymptotically valid confidence regions for a variety of inferential targets.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2021mestimator</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Kelly W and Janson, Lucas and Murphy, Susan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems (NeurIPS)}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Ranzato, M. and Beygelzimer, A. and Dauphin, Y. and Liang, P.S. and Vaughan, J. Wortman}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7460--7471}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Statistical Inference with M-Estimators on Adaptively Collected Data}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#5ac13a"> <div>Statistical Inference</div> </abbr> </div> <div id="zhang2020inference" class="col-sm-8"> <div class="title">Inference for Batched Bandits</div> <div class="author"> Kelly W Zhang, Lucas Janson, and Susan Murphy </div> <div class="periodical"> <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2002.03217" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.youtube.com/watch?v=iLJ1hC5k-IQ" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> <a href="https://github.com/kellywzhang/inference_batched_bandits" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>As bandit algorithms are increasingly utilized in scientific studies and industrial applications, there is an associated increasing need for reliable inference methods based on the resulting adaptively-collected data. In this work, we develop methods for inference on data collected in batches using a bandit algorithm. We first prove that the ordinary least squares estimator (OLS), which is asymptotically normal on independently sampled data, is not asymptotically normal on data collected using standard bandit algorithms when there is no unique optimal arm. This asymptotic non-normality result implies that the naive assumption that the OLS estimator is approximately normal can lead to Type-1 error inflation and confidence intervals with below-nominal coverage probabilities. Second, we introduce the Batched OLS estimator (BOLS) that we prove is (1) asymptotically normal on data collected from both multi-arm and contextual bandits and (2) robust to non-stationarity in the baseline reward.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2020inference</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Kelly W and Janson, Lucas and Murphy, Susan}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems (NeurIPS)}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Larochelle, H. and Ranzato, M. and Hadsell, R. and Balcan, M.F. and Lin, H.}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{9818--9829}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Inference for Batched Bandits}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{33}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?fa0110e8b42cec56ce96d912fd4bde74"></script> <script>addBackToTop();</script> </body> </html>